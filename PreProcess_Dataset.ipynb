{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cfyXA0HTy8Y"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets openai huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoTokenizer\n",
        "from huggingface_hub import HfApi, HfFolder\n",
        "import logging\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key = \"sk-proj-OpenAIKEY\")\n",
        "\n",
        "# Set up Hugging Face credentials\n",
        "hf_token = \"hf_HuggingfaceKey\"\n",
        "\n",
        "# Load the dataset from Hugging Face\n",
        "def load_hf_dataset(dataset_name, num_rows=100):\n",
        "    dataset = load_dataset(dataset_name)\n",
        "    df = pd.DataFrame(dataset['train'][:num_rows])  # Limit to num_rows\n",
        "    return df\n",
        "\n",
        "# Initialize tokenizer for token counting\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"LlamaFinetuneBase/Meta-Llama-3.1-8B-Instruct\")\n",
        "\n",
        "# Updated function to count tokens\n",
        "def count_tokens(instruction, input_text, output):\n",
        "    combined_text = f\"{instruction}\\n{input_text}\\n{output}\"\n",
        "    return len(tokenizer.encode(combined_text))\n",
        "\n",
        "# Function to categorize text using OpenAI API\n",
        "def categorize_text(text):\n",
        "    response = client.chat.completions.create(\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Categorize this text into one of the following categories, do not include the word 'Category' in your response only responsed with a single word: Programming, Small Talk, Technology, Science, Politics, Entertainment, Sports\\n\\n{text}\\n\\nCategory:\",\n",
        "        }],\n",
        "        model=\"gpt-4o-mini\",\n",
        "        max_tokens=3,\n",
        "        temperature=0.3,\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def score_text(text):\n",
        "    max_retries = 3\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                messages=[{\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": f\"Rate how well-formed and coherent this sentence is on a scale from 0 (poorly formed, incoherent) to 9 (well-formed, coherent). Consider grammar, clarity, and logical flow. Respond with ONLY an integer between 0 and 9:\\n\\n{text}\",\n",
        "                }],\n",
        "                model=\"gpt-4o-mini\",\n",
        "                max_tokens=2,\n",
        "                temperature=0.5,\n",
        "            )\n",
        "            content = response.choices[0].message.content.strip()\n",
        "            logging.info(f\"API response: {content}\")\n",
        "            return int(content)\n",
        "        except ValueError as e:\n",
        "            logging.warning(f\"Attempt {attempt + 1} failed: {e}\")\n",
        "            if attempt == max_retries - 1:\n",
        "                logging.error(f\"Failed to get a valid score after {max_retries} attempts. Returning 5 as default.\")\n",
        "                return 5\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Unexpected error: {e}\")\n",
        "            return 5\n",
        "        time.sleep(1)  # Wait for 1 second before retrying\n",
        "\n",
        "def score_training_quality(instruction, input, output):\n",
        "    prompt = f\"\"\"\n",
        "    Rate the quality of this instruction-input-output trio for training a language model (LLM) on a scale from 0 to 9, where 0 is very poor and 9 is excellent. Consider the following factors:\n",
        "\n",
        "    1. Clarity and specificity of the instruction\n",
        "    2. Relevance and usefulness of the input\n",
        "    3. Appropriateness and correctness of the output\n",
        "    4. Consistency between instruction, input, and output\n",
        "    5. Diversity and representativeness for LLM training\n",
        "    6. Potential for improving the model's capabilities\n",
        "\n",
        "    Respond with ONLY an integer between 0 and 9.\n",
        "\n",
        "    Instruction: {instruction}\n",
        "    Input: {input}\n",
        "    Output: {output}\n",
        "    \"\"\"\n",
        "    max_retries = 3\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                model=\"gpt-4o-mini\",\n",
        "                max_tokens=2,\n",
        "                temperature=0.5,\n",
        "            )\n",
        "            content = response.choices[0].message.content.strip()\n",
        "            logging.info(f\"Training quality score API response: {content}\")\n",
        "            return int(content)\n",
        "        except ValueError as e:\n",
        "            logging.warning(f\"Attempt {attempt + 1} failed: {e}\")\n",
        "            if attempt == max_retries - 1:\n",
        "                logging.error(f\"Failed to get a valid training quality score after {max_retries} attempts. Returning 5 as default.\")\n",
        "                return 5\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Unexpected error in scoring training quality: {e}\")\n",
        "            return 5\n",
        "        time.sleep(1)  # Wait for 1 second before retrying\n",
        "\n",
        "# Updated main processing function\n",
        "def process_dataset(df):\n",
        "    df['tokens'] = df.apply(lambda row: count_tokens(row['instruction'], row['input'], row['output']), axis=1)\n",
        "    df['response_score'] = df['output'].apply(score_text)\n",
        "    df['question_score'] = df['instruction'].apply(score_text)\n",
        "    df['category'] = df['instruction'].apply(categorize_text)\n",
        "    df['training_score'] = df.apply(lambda row: score_training_quality(row['instruction'], row['input'], row['output']), axis=1)\n",
        "    return df\n",
        "\n",
        "# Function to push dataset to Hugging Face Hub\n",
        "def push_to_hub(df, repo_name):\n",
        "    # Convert DataFrame to Hugging Face Dataset\n",
        "    dataset = Dataset.from_pandas(df)\n",
        "\n",
        "    # Push to Hub\n",
        "    dataset.push_to_hub(repo_name, token=hf_token)\n",
        "    logging.info(f\"Dataset pushed to Hugging Face Hub: {repo_name}\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    if not hf_token:\n",
        "        raise ValueError(\"HF_TOKEN environment variable not set. Please set your Hugging Face API token.\")\n",
        "\n",
        "    HfFolder.save_token(hf_token)\n",
        "    dataset_name = \"LlamaFinetuneBase/Notebook-Test\"\n",
        "    df = load_hf_dataset(dataset_name, num_rows=100)  # Load only 100 rows\n",
        "    processed_df = process_dataset(df)\n",
        "\n",
        "    # Push the processed dataset to Hugging Face Hub\n",
        "    push_to_hub(processed_df, \"LlamaFinetuneBase/Notebook-Test-Processed-100\")\n",
        "\n",
        "    print(\"Complete. Results saved and pushed to Hugging Face Hub.\")"
      ],
      "metadata": {
        "id": "D0MMkoXQTzSJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}